# ðŸš€ StratÃ©gie de Cache pour Manalytics

## ProblÃ¨me
Le systÃ¨me de Jiliac est plus efficace grÃ¢ce Ã  ses couches multiples :
- Cache centralisÃ© (pas de re-parsing)
- Processing C# compilÃ© (plus rapide)
- Distribution de charge

## Solution ProposÃ©e : Cache Local Intelligent

### Architecture Ã  2 Couches

```
Couche 1: Collection & Cache
â”œâ”€â”€ Scrapers (MTGO/Melee)
â”œâ”€â”€ Cache Processor
â”‚   â”œâ”€â”€ Parse raw JSON une fois
â”‚   â”œâ”€â”€ DÃ©tecte couleurs & archÃ©types
â”‚   â””â”€â”€ Sauve en cache optimisÃ©
â””â”€â”€ data/cache/
    â”œâ”€â”€ tournaments_cache.json     # MÃ©tadonnÃ©es
    â”œâ”€â”€ decklists_cache.parquet   # Format columnar
    â””â”€â”€ archetypes_cache.json      # RÃ©sultats

Couche 2: Analyse
â”œâ”€â”€ Cache Reader (ms)
â”œâ”€â”€ Analyzers
â””â”€â”€ Visualizers
```

### Format de Cache OptimisÃ©

```json
// tournaments_cache.json
{
  "last_updated": "2025-01-25T20:00:00Z",
  "tournaments": {
    "2025-01-15_standard-challenge-64": {
      "id": "12801190",
      "date": "2025-01-15",
      "format": "standard",
      "type": "challenge",
      "players": 64,
      "cache_file": "cache_20250115_12801190.parquet"
    }
  }
}
```

### Utilisation de Parquet
- Format columnar = lecture 10x plus rapide
- Compression native = 70% moins d'espace
- Support natif pandas = analyse rapide

### Workflow OptimisÃ©

1. **Scraping** (1x/jour)
   ```python
   raw_data = scrape_tournaments()
   ```

2. **Processing** (aprÃ¨s scraping)
   ```python
   for tournament in new_tournaments:
       decks = parse_tournament(tournament)
       colors = detect_colors_batch(decks)
       archetypes = detect_archetypes_batch(decks)
       save_to_cache(decks, colors, archetypes)
   ```

3. **Analyse** (instantanÃ©)
   ```python
   # Charge tout en <100ms
   cache = load_parquet_cache()
   analyze_metagame(cache)
   ```

### Avantages
- âœ… Parsing 1x seulement (comme Jiliac)
- âœ… Lecture ultra-rapide avec Parquet
- âœ… Pas de dÃ©pendance externe (GitHub)
- âœ… Cache incrÃ©mental (only new data)

### Implementation Phases

**Phase 1: Cache Simple** (2 jours)
- JSON cache basique
- DÃ©tection lors du scraping
- 5x plus rapide

**Phase 2: Cache Parquet** (3 jours)
- Migration vers Parquet
- Optimisations columnar
- 20x plus rapide

**Phase 3: Cache DistribuÃ©** (optionnel)
- Upload vers S3/GitHub
- CDN pour partage communautaire
- Comme Jiliac mais modernisÃ©